{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ba53cea",
   "metadata": {},
   "source": [
    "# Assignment 6\n",
    "\n",
    "The objective of this assignment is to compute the confidence interval of some performance measures of a server.\n",
    "\n",
    "## Characteristics\n",
    "The server is characterized by:\n",
    "- A **Hyper exponential** distribution of the **inter arrival time** with two stages ($ \\lambda_{1} $ = 0.1, $ \\lambda_{2} $ = 0.05, $ p_{1} $ = 0.5)\n",
    "- A **Hypo exponential** distribution of the **service time** with two stages ($ \\lambda_{1} $ = 0.1, $ \\lambda_{2} $ = 0.5)\n",
    "\n",
    "The assignment requires to plot the arrivals and the completions, and to compute a confidence interval for some performance indexes. \n",
    "\n",
    "The confidence interval considered is *95%* and must be computed for:\n",
    "- The average response time (**R**)\n",
    "- The average number of jobs (**N**)\n",
    "- The utilization (**U**)\n",
    "- The throughput (**X**)\n",
    "\n",
    "The number of jobs to generate is 10000 and they should be divided on 50 runs of 200 jobs each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378f870",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "First of all, we need to import the necessary libraries, tell ipython how to treat the generated plots and initialize the random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffbac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "\n",
    "rng = np.random.default_rng(seed = 0xdeadbeef)\n",
    "samples = 10000\n",
    "runs = 50\n",
    "ci = 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fff2053",
   "metadata": {},
   "source": [
    "## Generation\n",
    "We are now ready to generate the inter arrival samples and the service time samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4af67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## inter arrival time samples\n",
    "data1 = rng.random(size=samples)\n",
    "data2 = rng.random(size=samples)\n",
    "probabilities = rng.random(size=samples)\n",
    "inter_time_samples = []\n",
    "for i in range(0,samples):\n",
    "    if probabilities[i] < 0.5:\n",
    "        inter_time_samples.append(-np.log(data1[i])/0.1)\n",
    "    else:\n",
    "        inter_time_samples.append(-np.log(data2[i])/0.05)\n",
    "\n",
    "## service time samples\n",
    "data1 = rng.random(size=samples)\n",
    "data2 = rng.random(size=samples)\n",
    "service_times = - np.log(data1)/0.1 - np.log(data2)/0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ac340",
   "metadata": {},
   "source": [
    "## Arrivals and completions curves\n",
    "Next we are asked to plot the arrivals and the completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3817296c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_time_samples = np.cumsum(inter_time_samples)\n",
    "\n",
    "#completion_time_samples = np.add(arrival_time_samples, service_times)\n",
    "# This formula would be correct if we had the response times, not the service times.\n",
    "\n",
    "completion_time_samples = [arrival_time_samples[0]+service_times[0]]\n",
    "for i in range(1, samples):\n",
    "    if(arrival_time_samples[i]>completion_time_samples[i-1]):\n",
    "        completion_time_samples.append(arrival_time_samples[i]+service_times[i])\n",
    "    else:\n",
    "        completion_time_samples.append(completion_time_samples[i-1]+service_times[i])\n",
    "completion_time_samples = np.array(completion_time_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3703e7",
   "metadata": {},
   "source": [
    "The resulting plots are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65025c73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fc2ebaad2b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [*range(0,samples)]\n",
    "plt.step(arrival_time_samples, y, label='arrivals')\n",
    "plt.step(completion_time_samples, y, label='completions')\n",
    "# I don't need to put a sort on the completion time samples\n",
    "# since they are already sorted (you can check this by doing\n",
    "# print(all(completion_time_samples == sorted(completion time samples)))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89abeae2",
   "metadata": {},
   "source": [
    "## Confidence intervals\n",
    "The final requirement asks to compute the 95% confidence intervals for the performance measures listed above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f2925",
   "metadata": {},
   "source": [
    "### Service time\n",
    "To compute the service time confidence interval, we first need to compute the average and the variance of the service times sample set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115323c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_service_time = np.sum(service_times) / samples\n",
    "var_service_time = np.sum(np.power(service_times - avg_service_time,2))/(samples-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a61544",
   "metadata": {},
   "source": [
    "We can then compute the requested percentile of a student's t distribution with a degree of freedom equal to the number of samples we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7588624c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist = sps.t(samples)\n",
    "c_gamma = dist.ppf((1+ci)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650bb3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 95% probability, the average service time of the system will be between 11.757 and 12.154\n"
     ]
    }
   ],
   "source": [
    "lowr = avg_service_time - c_gamma * np.sqrt(np.divide(var_service_time, samples))\n",
    "uppr = avg_service_time + c_gamma * np.sqrt(np.divide(var_service_time, samples))\n",
    "ci_service = (lowr, uppr)\n",
    "print(\"With 95% probability, the average service time of the system will be between {:.3f} and {:.3f}\".format(ci_service[0], ci_service[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454023f8",
   "metadata": {},
   "source": [
    "Theoretically, if we repeat the experiment multiple times (or increase the number of rounds) __the mean of the distribution should be included in the confidence intervals just found about 95% of the times__. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5230089",
   "metadata": {},
   "source": [
    "Since the number of samples considered is greater than 30, instead of computing the quantiles from the Student's distribution samples, we can approximate them with the quantiles of a Standard Normal distribution.\n",
    "In our case, the 95% quantile of a standard normal distribution is 1.96."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "376eabbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 95% probability, the average service time of the system will be between 11.757 and 12.154\n"
     ]
    }
   ],
   "source": [
    "d_gamma = 1.96 \n",
    "# at this point already, when we confront d_gamma with c_gamma, we\n",
    "# can see that the values are really close.\n",
    "\n",
    "lowr = avg_service_time - d_gamma * np.sqrt(np.divide(var_service_time, samples))\n",
    "uppr = avg_service_time + d_gamma * np.sqrt(np.divide(var_service_time, samples))\n",
    "ci_service_norm = (lowr, uppr)\n",
    "print(\"With 95% probability, the average service time of the system will be between {:.3f} and {:.3f}\".format(ci_service_norm[0], ci_service_norm[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de127d41",
   "metadata": {},
   "source": [
    "### Response time\n",
    "To compute the response time confidence interval, we first need to compute the response times samples, their average and their variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc010cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_times = np.subtract(completion_time_samples, arrival_time_samples)\n",
    "avg_response_time = np.sum(response_times) / samples\n",
    "var_response_time = np.sum(np.power(response_times - avg_response_time,2))/(samples-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d452015a",
   "metadata": {},
   "source": [
    "Due to the same considerations written above, we can compute the confidence intervals from a Standard normal distribution (instead of a student's distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed27adfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 95% probability, the average response time of the system will be between 58.161 and 60.660\n"
     ]
    }
   ],
   "source": [
    "lowr = avg_response_time - d_gamma * np.sqrt(np.divide(var_response_time, samples))\n",
    "uppr = avg_response_time + d_gamma * np.sqrt(np.divide(var_response_time, samples))\n",
    "ci_response = (lowr, uppr)\n",
    "print(\"With 95% probability, the average response time of the system will be between {:.3f} and {:.3f}\".format(ci_response[0], ci_response[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e0f78",
   "metadata": {},
   "source": [
    "### Utilization\n",
    "Since utilization is not a performance index based on a mean-like formula, we cannot directly apply the method showed for the service time.\n",
    "\n",
    "We can instead split the sample dataset on multiple rounds (the number of rounds is given in the assignment), compute the utilization for each round and, given this array of utilizations, compute its confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ae624",
   "metadata": {},
   "source": [
    "Let's start by splitting the service times, the arrivals and the completions in rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "658099c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "service_times_runs = np.split(service_times, runs)\n",
    "arrival_runs = np.split(arrival_time_samples, runs)\n",
    "completion_runs = np.split(completion_time_samples, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc694b2e",
   "metadata": {},
   "source": [
    "Then, for each run, we can compute the busy time by summing up the service times.\n",
    "From there, the utilization is given by the formula $$U_{i} = \\frac{B_{i}}{T_{i}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fed6e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "busy_times_runs = np.sum(service_times_runs, 1)\n",
    "\n",
    "timespans = np.subtract(np.apply_along_axis(max, 1, completion_runs),\n",
    "            np.apply_along_axis(min, 1, arrival_runs))\n",
    "\n",
    "utilization_runs = []\n",
    "for i,busy in enumerate(busy_times_runs):\n",
    "    utilization_runs.append(busy/timespans[i])\n",
    "utilization_runs = np.array(utilization_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24d770d",
   "metadata": {},
   "source": [
    "Much like the service time case, we can now compute the confidence interval we need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "666085f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_utilization = np.sum(utilization_runs) / runs\n",
    "var_utilization = np.sum(np.power(utilization_runs - avg_utilization,2))/(runs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c3cb5ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dist = sps.t(50)\n",
    "c_gamma_runs = dist.ppf((1+ci)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e0f47aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 95% probability, the average utilization of the system will be between 0.759 and 0.805\n"
     ]
    }
   ],
   "source": [
    "lowr = avg_utilization - c_gamma_runs * np.sqrt(np.divide(var_utilization, runs))\n",
    "uppr = avg_utilization + c_gamma_runs * np.sqrt(np.divide(var_utilization, runs))\n",
    "ci_utilization = (lowr, uppr)\n",
    "print(\"With 95% probability, the average utilization of the system will be between {:.3f} and {:.3f}\".format(ci_utilization[0], ci_utilization[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475a78f9",
   "metadata": {},
   "source": [
    "### Number of jobs\n",
    "The computation of the confidence interval for the number of jobs is similar to the computation of the Utilization, except for the fact that we start from the response times (to compute $W$) and we use the formula $$N_{i} = \\frac{W_{i}}{T_{i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07a021",
   "metadata": {},
   "source": [
    "Let's start with the division of the response times in multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be730d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_times_runs = np.split(response_times, runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46685b",
   "metadata": {},
   "source": [
    "Next, we can compute the average number of jobs for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a4454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_runs = np.sum(response_times_runs, 1)\n",
    "numberj_runs = []\n",
    "for i,w in enumerate(w_runs):\n",
    "    numberj_runs.append(w/timespans[i])\n",
    "numberj_runs = np.array(numberj_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6eafec",
   "metadata": {},
   "source": [
    "Finally, given the formula showed above and the values obtained in the previous step, we can compute the confidence interval for the average number of jobs in the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "959159c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_numberj = np.sum(numberj_runs) / runs\n",
    "var_numberj = np.sum(np.power(numberj_runs - avg_numberj,2))/(runs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "526cd453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 95% probability, the average number of jobs in the system will be between 3.205 and 4.718\n"
     ]
    }
   ],
   "source": [
    "lowr = avg_numberj - c_gamma_runs * np.sqrt(np.divide(var_numberj, runs))\n",
    "uppr = avg_numberj + c_gamma_runs * np.sqrt(np.divide(var_numberj, runs))\n",
    "ci_numberj = (lowr, uppr)\n",
    "\n",
    "print(\"With 95% probability, the average number of jobs in the system will be between {:.3f} and {:.3f}\".format(ci_numberj[0], ci_numberj[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e406e0ab",
   "metadata": {},
   "source": [
    "### Throughput\n",
    "The computation of the confidence interval for the throughput is similar to the computation of the Utilization, except for the fact that we start from the number of completed jobs and we use the formula $$X_{i} = \\frac{C}{T_{i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b6bcc",
   "metadata": {},
   "source": [
    "Since we don't need any additional performance index, we can start with the conputation of the average throughput for each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "287ef01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_runs = [(samples/runs)/time for time in timespans]\n",
    "x_runs = np.array(x_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a66fc8a",
   "metadata": {},
   "source": [
    "We are now able to compute the confidence interval for the throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6872a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_throughput = np.sum(x_runs)/runs\n",
    "var_throughput = np.sum(np.power(x_runs - avg_throughput, 2))/(runs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ebedcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 95% probability, the average throughput of the system will be between 0.064 and 0.067\n"
     ]
    }
   ],
   "source": [
    "lowr = avg_throughput - c_gamma_runs * np.sqrt(np.divide(var_throughput, runs))\n",
    "uppr = avg_throughput + c_gamma_runs * np.sqrt(np.divide(var_throughput, runs))\n",
    "ci_throughput = (lowr, uppr)\n",
    "print(\"With 95% probability, the average throughput of the system will be between {:.3f} and {:.3f}\".format(ci_throughput[0], ci_throughput[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06db451a",
   "metadata": {},
   "source": [
    "## Summing up\n",
    "The confidence intervals we obtained are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13bc9f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Index   lower          upper          \n",
      "\n",
      "    S     11.7567        12.1535        \n",
      "    R     58.1611        60.6602        \n",
      "    N     3.2050         4.7176         \n",
      "    U     0.7589         0.8049         \n",
      "    X     0.0639         0.0668         \n"
     ]
    }
   ],
   "source": [
    "print(\"{!s: ^10}{!s:<15}{!s:<15}\\n\".format(\"Index\",\"lower\",\"upper\"))\n",
    "print(\"{!s: ^10}{:<15.4f}{:<15.4f}\".format(\"S\", ci_service[0], ci_service[1]))\n",
    "print(\"{!s: ^10}{:<15.4f}{:<15.4f}\".format(\"R\", ci_response[0], ci_response[1]))\n",
    "print(\"{!s: ^10}{:<15.4f}{:<15.4f}\".format(\"N\", ci_numberj[0], ci_numberj[1]))\n",
    "print(\"{!s: ^10}{:<15.4f}{:<15.4f}\".format(\"U\", ci_utilization[0], ci_utilization[1]))\n",
    "print(\"{!s: ^10}{:<15.4f}{:<15.4f}\".format(\"X\", ci_throughput[0], ci_throughput[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
